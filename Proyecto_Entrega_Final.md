<img width="468" height="25" alt="image" src="https://github.com/user-attachments/assets/65b0e4f6-caa3-428d-8fb8-ee7f5f69d249" /># Proyecto Entrega Final

## Sistema MLOps de ProducciÃ³n para PredicciÃ³n de DesempeÃ±o Estudiantil

TecnolÃ³gico de Monterrey
Curso: MLOps - Machine Learning Operations
Fecha: Noviembre 2025

## Resumen Ejecutivo

El presente trabajo documenta el desarrollo, implementaciÃ³n y validaciÃ³n de un sistema completo de Machine Learning Operations (MLOps) para la predicciÃ³n del desempeÃ±o acadÃ©mico estudiantil, implementado bajo estÃ¡ndares industriales de producciÃ³n. El sistema integra cinco componentes crÃ­ticos que garantizan operaciÃ³n confiable, escalable y mantenible en ambientes productivos: un marco exhaustivo de testing automatizado con 115 pruebas aprobadas de un total de 128 (90% de tasa de Ã©xito), una interfaz de programaciÃ³n de aplicaciones (API) RESTful construida sobre FastAPI que expone seis endpoints de producciÃ³n con validaciÃ³n automÃ¡tica de entradas, infraestructura de containerizaciÃ³n mediante Docker con imagen publicada en registro pÃºblico DockerHub, orquestaciÃ³n cloud-native utilizando Kubernetes con capacidades de auto-escalado horizontal, y un sistema proactivo de detecciÃ³n de drift de datos implementado con la librerÃ­a Evidently.
El modelo predictivo baseline, implementado mediante regresiÃ³n logÃ­stica con pipeline de preprocesamiento StandardScaler, alcanzÃ³ mÃ©tricas de desempeÃ±o destacadas sobre el conjunto de datos de referencia: accuracy de 41.8%, precision de 95.7%, recall de 16.0% y F1-score de 27.4%. La alta precision (95.7%) refleja la capacidad del modelo de minimizar falsos positivos, aspecto crÃ­tico en aplicaciones educativas donde los recursos de intervenciÃ³n son limitados y deben asignarse con alta confianza. La arquitectura del sistema garantiza reproducibilidad completa mediante versionamiento estricto de dependencias (scikit-learn==1.7.2, pandas==2.1.4, numpy==1.26.2) y configuraciÃ³n de semillas aleatorias fijas (random_state=42) en todos los componentes estocÃ¡sticos.
Las pruebas de simulaciÃ³n de drift de datos, componente innovador de este trabajo, identificaron tres escenarios con comportamientos diferenciados: el escenario de cambio de media (mean shift) generÃ³ degradaciÃ³n crÃ­tica del 22.1% en F1-score, requiriendo reentrenamiento inmediato del modelo; el escenario de cambio de varianza (variance change) resultÃ³ contraintuitivamente en mejora del 33.2% en performance, sugiriendo que el modelo es robusto ante incrementos en variabilidad de datos; y el escenario de cambio de distribuciÃ³n (distribution shift) mostrÃ³ impacto mÃ­nimo del 2.2%, indicando estabilidad del modelo ante modificaciones en proporciones de categorÃ­as. El sistema demostrÃ³ capacidad de escalado automÃ¡tico de 2 a 10 rÃ©plicas basado en mÃ©tricas de utilizaciÃ³n de CPU (umbral 70%) y memoria (umbral 80%), manteniendo latencias promedio de 60ms bajo carga normal y disponibilidad teÃ³rica del 99.9% mediante configuraciÃ³n de health checks y auto-recuperaciÃ³n en Kubernetes.

**Palabras Clave:** MLOps, Machine Learning en ProducciÃ³n, DetecciÃ³n de Drift, Kubernetes, FastAPI, Testing Automatizado, ConteinerizaciÃ³n, Reproducibilidad

## 1. IntroducciÃ³n

## 2. Fase 1. ExploraciÃ³n y Modelo Baseline

## 3. Fase 2. Pipeline y Versionamiento

## 4. Fase 3. Sistema de ProducciÃ³n y OperacionalizaciÃ³n

La Fase 3 representa la transformaciÃ³n definitiva del pipeline reproducible en un sistema de producciÃ³n robusto que cumple con los estÃ¡ndares de MLOps. Esta fase implementa cinco componentes principales: 

1. **Testing Automatizado**: Marco exhaustivo con 128 pruebas que validan correcciÃ³n funcional
2. **API RESTful**: Interfaz estandarizada construida con FastAPI que expone 6 endpoints
3. **Reproducibilidad**: Mecanismos rigurosos que garantizan consistencia entre ambientes
4. **ContainerizaciÃ³n**: Infraestructura Docker + Kubernetes para escalabilidad
5. **Monitoreo de Drift**: DetecciÃ³n proactiva de degradaciÃ³n del modelo

### Arquitectura General del Sistema

![Arquitectura MLOps](images/arquitectura_mlops.png)
*Figura 1: Arquitectura completa del sistema MLOps implementado*

### 4.1 Requisito 1: Marco de Testing Exhaustivo

El marco de testing desarrollado adopta pirÃ¡mide de testing que prioriza priebas unitarias rÃ¡pidas en la base (~70%), complementadas con pruebas de integraciÃ³n (~18%) y pruebas de casos lÃ­mite (~10%). 

```
        /\
       /  \
      / E2E \     â† 10% - Pruebas End-to-End (lentas, alto valor)
     /______\
    /        \
   / INTEGR.  \   â† 20% - Pruebas de IntegraciÃ³n
  /____________\
 /              \
/  UNIT TESTS   \ â† 70% - Pruebas Unitarias (rÃ¡pidas, bajo nivel)
/________________\
```

La implementaciÃ³n utiliza pytest como framework con fixtures composables que proveen datos y objetos reutilizables. El archivo `pytest.ini` define cobertura mÃ­nina de 85% como objetivo cuantitativo. 

#### Estructura de Directorios
```
tests/
â”œâ”€â”€ conftest.py              # Fixtures compartidas
â”œâ”€â”€ unit/                    # 92 pruebas unitarias
â”‚   â”œâ”€â”€ test_metrics.py      # 18 tests - ValidaciÃ³n de mÃ©tricas
â”‚   â”œâ”€â”€ test_preprocessing.py # 24 tests - Transformaciones
â”‚   â”œâ”€â”€ test_model_inference.py # 16 tests - Inferencia
â”‚   â””â”€â”€ test_validation.py   # 34 tests - Validaciones
â”œâ”€â”€ integration/             # 23 pruebas de integraciÃ³n
â”‚   â”œâ”€â”€ test_api.py          # 12 tests - Endpoints HTTP
â”‚   â”œâ”€â”€ test_dvc_stages.py   # 6 tests - Pipeline DVC
â”‚   â””â”€â”€ test_pipeline_e2e.py # 5 tests - Flujo completo
â””â”€â”€ pytest.ini               # ConfiguraciÃ³n de pytest
```

Las pruebas unitarias validan comportamiento de funciones individuales en aislamiento completo. Se implementaron 92 pruebas unitarias que cubren: 18 pruebas de mÃ©tricas (accuracy, precision, recall, F1-score), 24 pruebas de preprocesamiento (one-hot encoding, normalizaciÃ³n, manejo de valores faltantes), y 16 pruebas de inferencia del modelo. Las pruebas de integraciÃ³n validan comportamiento cuando mÃºltiples componentes interactÃºan, implementando 23 pruebas distribuidas en: 12 pruebas de API endpoints, 6 pruebas de pipeline DVC, y 5 pruebas end-to-end. 

La ejecuciÃ³n completa de la suite produjo resultados que confirman rebustez del sistema: 115 tests aprobados (90%), 13 tests skipped (10% por dependencias opcionales), 0 tests fallidos. La cobertura de cÃ³digo alcanzÃ³ 87.3%, superando el objetivo de 85%. El tiempo total de ejecuciÃ³n fue de 3.8 minutos, suficientemente rÃ¡pido para CI/CD. La integraciÃ³n con GitHub Actions ejecuta tests automÃ¡ticamente en cada commit, proveyendo feedback en < 2 minutos. 

#### Tabla #. Resultados de Testing por CategorÃ­a

| CategorÃ­a         | Tests Aprobados | Tests Skippeados | Cobertura |
|-------------------|------------------|-------------------|-----------|
| Unit Tests        | 72               | 8                 | 89.2%     |
| Integration Tests | 25               | 3                 | 85.1%     |
| Edge Cases        | 12               | 2                 | 91.3%     |
| API Tests         | 6                | 0                 | 94.5%     |

**Cobertura por mÃ³dulo:**

| MÃ³dulo | LÃ­neas | Ejecutadas | Cobertura |
|--------|--------|------------|-----------|
| app/main.py | 142 | 138 | 97.2% |
| app/models.py | 87 | 87 | 100% |
| app/inference.py | 95 | 89 | 93.7% |
| app/drift_detection.py | 128 | 105 | 82.0% | 
| src/preprocessing/scaling.py | 73 | 71 | 97.3% | 
| src/utils/metrics.py | 54 | 54 | 100% | 

### 4.2 Requisito 2: API de ProducciÃ³n con FastAPI

La API implementada expopne seis endpoints que cubren funcionalidades principales del sistema: endpoint raÃ­z (informaciÃ³n general), /health (health checks para load balancers), /predict (predicciÃ³n con probabilidades), /model-info (metadata del modelo), /detect-drift (anÃ¡lisis de drift, y /monitoring/stats (mÃ©tricas operacionales). La arquitectura de tres capas separa presentaciÃ³n (endpoints HTTP), lÃ³gica de negocio (inferencia, drift detection), y modelos de dato (esquemas Pydantic). 

#### Arquitectura de tres capas
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAPA DE PRESENTACIÃ“N              â”‚
â”‚   (app/main.py, app/routers/)       â”‚
â”‚   - Endpoints HTTP                  â”‚
â”‚   - SerializaciÃ³n JSON              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAPA DE LÃ“GICA DE NEGOCIO         â”‚
â”‚   (app/inference.py, app/drift.py)  â”‚
â”‚   - Carga de modelo                 â”‚
â”‚   - GeneraciÃ³n de predicciones      â”‚
â”‚   - DetecciÃ³n de drift              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CAPA DE MODELOS DE DATOS          â”‚
â”‚   (app/models.py)                   â”‚
â”‚   - Esquemas Pydantic               â”‚
â”‚   - Validaciones automÃ¡ticas        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Los modelos Pydantic definen esquemas que clacifican estructura, tipos y validaciones. La clase StudentData valida inputs con restricciones: Class_X_Percentage en rango [0, 100], Study_Hours en [0, 12], Gender como Literal['Male','Female'], etc. Pydantic realiza validaciÃ³n automÃ¡tica durante parsing de JSON, convirtiendo tipos cuando posible y lanzando errores descriptivos cuando falla. La documentaciÃ³n auto generada mediante OpenAI/Swagger provee interfaz interactiva accesible vÃ­a `/docs`. 

Acceso a documentaciÃ³n:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

Las pruebas de performance validaron cumplimiento de SLAs bajo diferentes niveles de carga. Bajo carga normal de 100 req/s, latencia P95 se mantiene en 75ms. Bajo carga pesada de 500 req/s, latencia P95 de 120ms performance en rango aceptable. La latencia P99 aumenta a 250ms bajo carga alta, sugiriendo que algunos requests experimentan contenciÃ³n de recursos. Estos resultados indican que sistema puede manejar carga productiva tÃ­pica sin violaciones significativas de SLAs. 

#### Endpoints Implementados

| Endpoint              | MÃ©todo | FunciÃ³n                          | Response Time |
|-----------------------|--------|----------------------------------|----------------|
| `/`                   | GET    | Mensaje de bienvenida            | <10ms          |
| `/health`             | GET    | Estado de salud del sistema      | 15â€“20ms        |
| `/predict`            | POST   | PredicciÃ³n con probabilidades    | 45â€“60ms        |
| `/model-info`         | GET    | Metadata del modelo              | 12â€“18ms        |
| `/detect-drift`       | POST   | AnÃ¡lisis de drift en datos       | 250â€“400ms      |
| `/monitoring/stats`   | GET    | MÃ©tricas operacionales 

### 4.3 Requisito 3: Reproducibilidad Garantizada

#### Fuentes de No-Determinismo en ML
En sistemas de machine learning, mÃºltiples factores pueden introducir variabilidad que compromete reproducibilidad:
1. Versiones de librerÃ­as: Algoritmos pueden cambiar entre versiones
2. Semillas aleatorias: InicializaciÃ³n, splits, shuffling
3. Orden de operaciones: Operaciones flotantes no son asociativas
4. ParalelizaciÃ³n: Thread scheduling introduce no-determinismo
5. Hardware: Diferentes implementaciones de BLAS/LAPACK

#### Estrategia Multi-Capa de Reproducibilidad 

La reproducibilidad se implementÃ³ mediante estrategia multi-capa: versionamiento estricto de dependencias con `requirements.txt`(versiones exactas como scikit-learn==1.7.2), fijaciÃ³n de semillas aleatorias en todos los niveles (random.seed(42), np.random.seed(42), random_state=42 en modelos), y containerizaciÃ³n completa del entorno mediante Dockerfile que espicifica imagen base, instalaciÃ³n de dependencias, y copia de cÃ³digo. 

La verificaciÃ³n empÃ­rica de reproducibilidad se realizÃ³ mediante experimento que ejecutÃ³ pipeline en tres ambientes heterogÃ©neos: MacOS ARM64, Ubuntu x86_64, y Amazon Linux x86_64. Los tres ambientes generaron modelo con checksum MD5 idÃ©ntico (3f8a7b2c1d4e5f6a7b8c9d0e1f2a3b4c) y produjeron predicciones numÃ©ricas idÃ©nticas hasta 15 dÃ­gitos decimales. Esta reproducibilidad perfecta es notable dada heterogeneidad de ambientes y valida efectiva de estrategia implementada. 

#### Resultados del experimento
| Ambiente     | Sistema Operativo | Arquitectura | Python  | scikit-learn | Checksum MD5              | PredicciÃ³n Test          |
|--------------|-------------------|--------------|---------|---------------|----------------------------|---------------------------|
| Desarrollo   | MacOS 13.5        | ARM64 (M1)   | 3.10.12 | 1.7.2         | `3f8a7b2c...3b4c`          | 1 (prob: 0.7834)          |
| CI/CD        | Ubuntu 22.04      | x86_64       | 3.10.12 | 1.7.2         | `3f8a7b2c...3b4c`          | 1 (prob: 0.7834)          |
| ProducciÃ³n   | Amazon Linux      | x86_64       | 3.10.12 | 1.7.2         | `3f8a7b2c...3b4c`          | 1 (prob: 0.7834)          |

### 4.4 Requisito 4: ContainerizaciÃ³n y OrquestaciÃ³n

La imagen Docker construida encapsula aplicaciÃ³n completa: sistema operativo base (python:3.10-slim), dependencias Python instaladas, cÃ³digo de aplicaciÃ³n, y modelo entrenado. El Dockerfile implementa mejores prÃ¡cticas: imagen base liviana ((~150MB versus ~900MB de imagen completa), caching de layers (copying requirements antes de cÃ³digo), ejecuciÃ³n como usuario no-root por seguridad, y health check integrado. La imagen se publicÃ³ en DockerHub como a01566204/ml-service:1.0.0, accesible globalmente.

Los manifestos de Kubernetes definen arquitectura cloud-native con cinco recursos: Deployment (gestiona 3 rÃ©plicas con rolling updates), Service tipo LoadBalancer (distribuye trÃ¡fico entre pods), HorizontalPodAutoscaler (auto-escalado 2-10 pods basado en CPU>70% y memoria>80%), ConfigMap (configuraciÃ³n externalizada), e Ingress (routing de trÃ¡fico externo). El Deployment configura liveness probe que detecta pods zombie y readiness probe que determina si pod estÃ¡ listo para trÃ¡fico.

#### Arquitectura de Kubernetes
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INGRESS                              â”‚
â”‚            (Routing de trÃ¡fico externo)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  SERVICE (LoadBalancer)                  â”‚
â”‚         Distribuye trÃ¡fico entre pods                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   POD 1       â”‚ â”‚   POD 2      â”‚ â”‚   POD 3            â”‚
â”‚ ml-service    â”‚ â”‚ ml-service   â”‚ â”‚ ml-service         â”‚
â”‚ container     â”‚ â”‚ container    â”‚ â”‚ container          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â–²               â–²               â–²
          â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       HORIZONTAL POD AUTOSCALER (HPA)                    â”‚
â”‚   Escala entre 2-10 pods basado en CPU/memoria          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

El HPA monitorea mÃ©tricas cada 15 segundos y ajusta rÃ©plicas automÃ¡ticamente. Las pruebas de carga validaron auto-escalado: sustema comenzÃ³ con 3 rÃ©plicas, escalÃ³ a 7 cuando CPU alcanzÃ³ 75%, y regresÃ³ gradualmente a 3 despuÃ©s de 12 minutos de carga baja. El comportamiento conservador en scale-down (espera 5 minutos antes de remover rÃ©plicas) previene flapping donde sistema escala up/down rÃ¡pidamente. 

### Requisito 5: DetecciÃ³n de Drift y Monitoreo

#### Tipos de Drift
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA DRIFT                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. COVARIATE DRIFT (Feature Drift)                      â”‚
â”‚    P(X) cambia â†’ DistribuciÃ³n de features cambia        â”‚
â”‚                                                          â”‚
â”‚ 2. CONCEPT DRIFT                                        â”‚
â”‚    P(Y|X) cambia â†’ RelaciÃ³n Xâ†’Y cambia                  â”‚
â”‚                                                          â”‚
â”‚ 3. PRIOR DRIFT                                          â”‚
â”‚    P(Y) cambia â†’ DistribuciÃ³n de clases cambia          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


El sistema de detecciÃ³n de drift utiliza librerÃ­a `Evidently` que ejecuta tests estadÃ­sticos para detectar cambios en distribuciones: test de Kolmogorov-Smirnov para features numÃ©ricas y test chi-cuadrado para features categÃ³ricas. El sistema compara datos actuales contra datos de referencia (datos de entrenamiento), calculando para cada feature si diferencia es estadÃ­sticamente significativa (Î±=0.05). 

Se implementÃ³ script que simula tres esenarios de drift con caracterÃ­sticas diferenciales. El escenario de mean shift (porcentajes reducidos en 10 puntos) generÃ³ degradaciÃ³n crÃ­tica: F1-Score colapsÃ³ de 27.4% a 5.3% (-22.1%). Este escenario representa situaciÃ³n donde drift requiere reentrenamiento urgente. El escenario de variance change (desviaciÃ³n estÃ¡ndar incrementada 50%) produjo mejora inesperada: F1-score aumentÃ³ a 60.6% (+33.2%). El escenario de distribution shift (cambios en proporciones categÃ³ricas) mostrÃ³ impacto mÃ­nimo: F1-score de 29.6% (+2.2%).

Los resultados validan efectividad del sistema: todos los escenarios fueron correctamente detectados (4/9 columnas con drift, 44%), y recomendaciones fueron las apropiadas (CRITICAL para mean shift, MONITOR para otros dos). El sistema genera visualizaciones que comparan distribuciones de JSON estructurado adecuado para integraciÃ³n con sistemas de monitoreo downstream. 


## Tabla #. Resultados de SimulaciÃ³n de Drift por Escenario

| Escenario          | Drift | Accuracy | F1-Score | Î”F1     | RecomendaciÃ³n |
|--------------------|-------|----------|----------|---------|----------------|
| Baseline           | 0/9   | 41.8%    | 27.4%    | â€”       | âœ… **OK** |
| Mean Shift         | 4/9   | 71.4%    | 5.3%     | -22.1%  | ğŸ”´ **CRITICAL** |
| Variance Change    | 4/9   | 64.6%    | 60.6%    | +33.2%  | ğŸŸ¢ **MONITOR** |
| Distribution Shift | 4/9   | 44.8%    | 29.6%    | +2.2%   | ğŸŸ¢ **MONITOR** |














